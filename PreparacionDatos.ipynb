{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Instalación de librerias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: contractions in /home/valentina/anaconda3/lib/python3.7/site-packages (0.1.72)\r\n",
      "Requirement already satisfied: textsearch>=0.0.21 in /home/valentina/anaconda3/lib/python3.7/site-packages (from contractions) (0.0.24)\r\n",
      "Requirement already satisfied: anyascii in /home/valentina/anaconda3/lib/python3.7/site-packages (from textsearch>=0.0.21->contractions) (0.3.1)\r\n",
      "Requirement already satisfied: pyahocorasick in /home/valentina/anaconda3/lib/python3.7/site-packages (from textsearch>=0.0.21->contractions) (1.4.4)\r\n"
     ]
    }
   ],
   "source": [
    "# Librería para manejar las contracciones que se presentan en el inglés.\n",
    "!pip install contractions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting inflect\n",
      "  Downloading https://files.pythonhosted.org/packages/d3/0f/c51780fb99b156e998a8bcbc418aea9179ccd301f8c2a8c1bb255c294af6/inflect-6.0.0-py3-none-any.whl\n",
      "Collecting pydantic (from inflect)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d4/ec/230ab377c457cd68cfda78759e2a57f8c08a9e9adb4cd53c4d2fc9100b15/pydantic-1.10.2-py3-none-any.whl (154kB)\n",
      "\u001b[K     |████████████████████████████████| 163kB 788kB/s eta 0:00:01\n",
      "\u001b[?25hCollecting typing-extensions>=4.1.0 (from pydantic->inflect)\n",
      "  Downloading https://files.pythonhosted.org/packages/0b/8e/f1a0a5a76cfef77e1eb6004cb49e5f8d72634da638420b9ea492ce8305e8/typing_extensions-4.4.0-py3-none-any.whl\n",
      "\u001b[31mERROR: tensorflow 2.4.1 has requirement typing-extensions~=3.7.4, but you'll have typing-extensions 4.4.0 which is incompatible.\u001b[0m\n",
      "Installing collected packages: typing-extensions, pydantic, inflect\n",
      "  Found existing installation: typing-extensions 3.7.4.3\n",
      "    Uninstalling typing-extensions-3.7.4.3:\n",
      "      Successfully uninstalled typing-extensions-3.7.4.3\n",
      "Successfully installed inflect-6.0.0 pydantic-1.10.2 typing-extensions-4.4.0\n",
      "Collecting pandas-profiling==2.7.1\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/50/8a/25da481171f4912e2515a76fe31b7a4f036a443b8858b244ef7daaffd5b6/pandas_profiling-2.7.1-py2.py3-none-any.whl (252kB)\n",
      "\u001b[K     |████████████████████████████████| 256kB 47kB/s eta 0:00:011\n",
      "\u001b[?25hCollecting scipy>=1.4.1 (from pandas-profiling==2.7.1)\n",
      "  Using cached https://files.pythonhosted.org/packages/58/4f/11f34cfc57ead25752a7992b069c36f5d18421958ebd6466ecd849aeaf86/scipy-1.7.3-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl\n",
      "Collecting astropy>=4.0 (from pandas-profiling==2.7.1)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/39/6e/04fba8c047000e3d9f09879f4e24ff805edbc4bb3943ec3a31e18ed6cad4/astropy-4.3.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (10.7MB)\n",
      "\u001b[K     |████████████████████████████████| 10.7MB 764kB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: tqdm>=4.43.0 in /home/valentina/anaconda3/lib/python3.7/site-packages (from pandas-profiling==2.7.1) (4.63.0)\n",
      "Collecting pandas!=1.0.0,!=1.0.1,!=1.0.2,>=0.25.3 (from pandas-profiling==2.7.1)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/99/f0/f99700ef327e51d291efdf4a6de29e685c4d198cbf8531541fc84d169e0e/pandas-1.3.5.tar.gz (4.7MB)\n",
      "\u001b[K     |████████████████████████████████| 4.7MB 847kB/s eta 0:00:01\n",
      "\u001b[?25h  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h    Preparing wheel metadata ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting visions[type_image_path]==0.4.1 (from pandas-profiling==2.7.1)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/13/fe/7614dec3db3f20882ff12dae0a58b579e97b590f2994ce9c953fe179d512/visions-0.4.1-py3-none-any.whl (58kB)\n",
      "\u001b[K     |████████████████████████████████| 61kB 6.0MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting matplotlib>=3.2.0 (from pandas-profiling==2.7.1)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ad/62/7b662284352867a86acfb636761ba351723fc3a235efd8397578d903413d/matplotlib-3.5.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.whl (11.2MB)\n",
      "\u001b[K     |████████████████████████████████| 11.2MB 1.3MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.16.0 in /home/valentina/anaconda3/lib/python3.7/site-packages (from pandas-profiling==2.7.1) (1.19.5)\n",
      "Collecting tangled-up-in-unicode>=0.0.4 (from pandas-profiling==2.7.1)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/dd/60/3651960b74aead282ec1ad819e70bdccf3ee73322d13d4339a6e3f5b7ed3/tangled_up_in_unicode-0.2.0-py3-none-any.whl (4.7MB)\n",
      "\u001b[K     |████████████████████████████████| 4.7MB 1.5MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting jinja2>=2.11.1 (from pandas-profiling==2.7.1)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/bc/c3/f068337a370801f372f2f8f6bad74a5c140f6fda3d9de154052708dd3c65/Jinja2-3.1.2-py3-none-any.whl (133kB)\n",
      "\u001b[K     |████████████████████████████████| 133kB 1.2MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting phik>=0.9.10 (from pandas-profiling==2.7.1)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/2e/6c/2ec53b5ea4cb6aee603de707599f30aada1ff3264b954fd8424e2ad40964/phik-0.12.2.tar.gz (602kB)\n",
      "\u001b[K     |████████████████████████████████| 604kB 2.4MB/s eta 0:00:01\n",
      "\u001b[?25h  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h    Preparing wheel metadata ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting htmlmin>=0.1.12 (from pandas-profiling==2.7.1)\n",
      "  Downloading https://files.pythonhosted.org/packages/b3/e7/fcd59e12169de19f0131ff2812077f964c6b960e7c09804d30a7bf2ab461/htmlmin-0.1.12.tar.gz\n",
      "Collecting ipywidgets>=7.5.1 (from pandas-profiling==2.7.1)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e4/56/990c10ca8751182ace2464cb0e4baafb7087a40c185c9142b9cd18683fac/ipywidgets-8.0.2-py3-none-any.whl (134kB)\n",
      "\u001b[K     |████████████████████████████████| 143kB 475kB/s eta 0:00:01\n",
      "\u001b[?25hCollecting missingno>=0.4.2 (from pandas-profiling==2.7.1)\n",
      "  Downloading https://files.pythonhosted.org/packages/17/a2/be45b3bd2fe14cf9173f2337ab87a0f877d6847cf097e641eab4811a8b02/missingno-0.5.1-py3-none-any.whl\n",
      "Collecting requests>=2.23.0 (from pandas-profiling==2.7.1)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ca/91/6d9b8ccacd0412c08820f72cebaa4f0c0441b5cda699c90f618b6f8a1b42/requests-2.28.1-py3-none-any.whl (62kB)\n",
      "\u001b[K     |████████████████████████████████| 71kB 4.8MB/s eta 0:00:011\n",
      "\u001b[?25hRequirement already satisfied: joblib in /home/valentina/anaconda3/lib/python3.7/site-packages (from pandas-profiling==2.7.1) (0.13.2)\n",
      "Collecting confuse>=1.0.0 (from pandas-profiling==2.7.1)\n",
      "  Downloading https://files.pythonhosted.org/packages/77/db/3c0594c0341d1dd095d685c73f49507b2e5392c7588fd893d07a4c5d959f/confuse-2.0.0-py3-none-any.whl\n",
      "Collecting pyerfa>=1.7.3 (from astropy>=4.0->pandas-profiling==2.7.1)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/8f/76/68d862db9bd200776a3fa60d2c07fcee34285e5363adb88fdd8fbc3bce36/pyerfa-2.0.0.1-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (746kB)\n",
      "\u001b[K     |████████████████████████████████| 747kB 942kB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: importlib-metadata; python_version == \"3.7\" in /home/valentina/anaconda3/lib/python3.7/site-packages (from astropy>=4.0->pandas-profiling==2.7.1) (0.17)\n",
      "Requirement already satisfied: pytz>=2017.3 in /home/valentina/anaconda3/lib/python3.7/site-packages (from pandas!=1.0.0,!=1.0.1,!=1.0.2,>=0.25.3->pandas-profiling==2.7.1) (2019.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /home/valentina/anaconda3/lib/python3.7/site-packages (from pandas!=1.0.0,!=1.0.1,!=1.0.2,>=0.25.3->pandas-profiling==2.7.1) (2.8.0)\n",
      "Collecting attrs>=19.3.0 (from visions[type_image_path]==0.4.1->pandas-profiling==2.7.1)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f2/bc/d817287d1aa01878af07c19505fafd1165cd6a119e9d0821ca1d1c20312d/attrs-22.1.0-py2.py3-none-any.whl (58kB)\n",
      "\u001b[K     |████████████████████████████████| 61kB 1.1MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting networkx>=2.4 (from visions[type_image_path]==0.4.1->pandas-profiling==2.7.1)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e9/93/aa6613aa70d6eb4868e667068b5a11feca9645498fd31b954b6c4bb82fa5/networkx-2.6.3-py3-none-any.whl (1.9MB)\n",
      "\u001b[K     |████████████████████████████████| 1.9MB 587kB/s eta 0:00:01\n",
      "\u001b[?25hCollecting imagehash; extra == \"type_image_path\" (from visions[type_image_path]==0.4.1->pandas-profiling==2.7.1)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/2d/b4/19a746a986c6e38595fa5947c028b1b8e287773dcad766e648897ad2a4cf/ImageHash-4.3.1-py2.py3-none-any.whl (296kB)\n",
      "\u001b[K     |████████████████████████████████| 296kB 1.4MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: Pillow; extra == \"type_image_path\" in /home/valentina/anaconda3/lib/python3.7/site-packages (from visions[type_image_path]==0.4.1->pandas-profiling==2.7.1) (6.1.0)\n",
      "Collecting packaging>=20.0 (from matplotlib>=3.2.0->pandas-profiling==2.7.1)\n",
      "  Using cached https://files.pythonhosted.org/packages/05/8e/8de486cbd03baba4deef4142bd643a3e7bbe954a784dc1bb17142572d127/packaging-21.3-py3-none-any.whl\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyparsing>=2.2.1 in /home/valentina/anaconda3/lib/python3.7/site-packages (from matplotlib>=3.2.0->pandas-profiling==2.7.1) (2.4.0)\n",
      "Collecting fonttools>=4.22.0 (from matplotlib>=3.2.0->pandas-profiling==2.7.1)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/59/73/d8f2d961ecd548685d770fb005e355514573d2108d8ed9460d7a1f1870b5/fonttools-4.37.4-py3-none-any.whl (960kB)\n",
      "\u001b[K     |████████████████████████████████| 962kB 1.6MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: kiwisolver>=1.0.1 in /home/valentina/anaconda3/lib/python3.7/site-packages (from matplotlib>=3.2.0->pandas-profiling==2.7.1) (1.1.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/valentina/anaconda3/lib/python3.7/site-packages (from matplotlib>=3.2.0->pandas-profiling==2.7.1) (0.10.0)\n",
      "Collecting MarkupSafe>=2.0 (from jinja2>=2.11.1->pandas-profiling==2.7.1)\n",
      "  Downloading https://files.pythonhosted.org/packages/1d/97/2288fe498044284f39ab8950703e88abbac2abbdf65524d576157af70556/MarkupSafe-2.1.1.tar.gz\n",
      "Collecting widgetsnbextension~=4.0 (from ipywidgets>=7.5.1->pandas-profiling==2.7.1)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d7/ae/ee70b20dc836d935a9a6483339854c09d8752e55a8104668e2426cf3baf3/widgetsnbextension-4.0.3-py3-none-any.whl (2.0MB)\n",
      "\u001b[K     |████████████████████████████████| 2.0MB 3.5MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting jupyterlab-widgets~=3.0 (from ipywidgets>=7.5.1->pandas-profiling==2.7.1)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d8/52/2f4b8f5975312fb58f4eacab2e6f6cfd2efd05704514a60a151a4e69d608/jupyterlab_widgets-3.0.3-py3-none-any.whl (384kB)\n",
      "\u001b[K     |████████████████████████████████| 389kB 1.2MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: ipykernel>=4.5.1 in /home/valentina/anaconda3/lib/python3.7/site-packages (from ipywidgets>=7.5.1->pandas-profiling==2.7.1) (5.1.1)\n",
      "Requirement already satisfied: traitlets>=4.3.1 in /home/valentina/anaconda3/lib/python3.7/site-packages (from ipywidgets>=7.5.1->pandas-profiling==2.7.1) (4.3.2)\n",
      "Requirement already satisfied: ipython>=6.1.0 in /home/valentina/anaconda3/lib/python3.7/site-packages (from ipywidgets>=7.5.1->pandas-profiling==2.7.1) (7.6.1)\n",
      "Requirement already satisfied: seaborn in /home/valentina/anaconda3/lib/python3.7/site-packages (from missingno>=0.4.2->pandas-profiling==2.7.1) (0.9.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/valentina/anaconda3/lib/python3.7/site-packages (from requests>=2.23.0->pandas-profiling==2.7.1) (1.24.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/valentina/anaconda3/lib/python3.7/site-packages (from requests>=2.23.0->pandas-profiling==2.7.1) (2.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/valentina/anaconda3/lib/python3.7/site-packages (from requests>=2.23.0->pandas-profiling==2.7.1) (2019.6.16)\n",
      "Collecting charset-normalizer<3,>=2 (from requests>=2.23.0->pandas-profiling==2.7.1)\n",
      "  Downloading https://files.pythonhosted.org/packages/db/51/a507c856293ab05cdc1db77ff4bc1268ddd39f29e7dc4919aa497f0adbec/charset_normalizer-2.1.1-py3-none-any.whl\n",
      "Requirement already satisfied: pyyaml in /home/valentina/anaconda3/lib/python3.7/site-packages (from confuse>=1.0.0->pandas-profiling==2.7.1) (5.1.1)\n",
      "Requirement already satisfied: zipp>=0.5 in /home/valentina/anaconda3/lib/python3.7/site-packages (from importlib-metadata; python_version == \"3.7\"->astropy>=4.0->pandas-profiling==2.7.1) (0.5.1)\n",
      "Requirement already satisfied: six>=1.5 in /home/valentina/anaconda3/lib/python3.7/site-packages (from python-dateutil>=2.7.3->pandas!=1.0.0,!=1.0.1,!=1.0.2,>=0.25.3->pandas-profiling==2.7.1) (1.15.0)\n",
      "Requirement already satisfied: PyWavelets in /home/valentina/anaconda3/lib/python3.7/site-packages (from imagehash; extra == \"type_image_path\"->visions[type_image_path]==0.4.1->pandas-profiling==2.7.1) (1.0.3)\n",
      "Requirement already satisfied: setuptools in /home/valentina/anaconda3/lib/python3.7/site-packages (from kiwisolver>=1.0.1->matplotlib>=3.2.0->pandas-profiling==2.7.1) (41.0.1)\n",
      "Requirement already satisfied: tornado>=4.2 in /home/valentina/anaconda3/lib/python3.7/site-packages (from ipykernel>=4.5.1->ipywidgets>=7.5.1->pandas-profiling==2.7.1) (6.0.3)\n",
      "Requirement already satisfied: jupyter-client in /home/valentina/anaconda3/lib/python3.7/site-packages (from ipykernel>=4.5.1->ipywidgets>=7.5.1->pandas-profiling==2.7.1) (5.3.1)\n",
      "Requirement already satisfied: decorator in /home/valentina/anaconda3/lib/python3.7/site-packages (from traitlets>=4.3.1->ipywidgets>=7.5.1->pandas-profiling==2.7.1) (4.4.0)\n",
      "Requirement already satisfied: ipython-genutils in /home/valentina/anaconda3/lib/python3.7/site-packages (from traitlets>=4.3.1->ipywidgets>=7.5.1->pandas-profiling==2.7.1) (0.2.0)\n",
      "Requirement already satisfied: pygments in /home/valentina/anaconda3/lib/python3.7/site-packages (from ipython>=6.1.0->ipywidgets>=7.5.1->pandas-profiling==2.7.1) (2.4.2)\n",
      "Requirement already satisfied: pexpect; sys_platform != \"win32\" in /home/valentina/anaconda3/lib/python3.7/site-packages (from ipython>=6.1.0->ipywidgets>=7.5.1->pandas-profiling==2.7.1) (4.7.0)\n",
      "Requirement already satisfied: prompt-toolkit<2.1.0,>=2.0.0 in /home/valentina/anaconda3/lib/python3.7/site-packages (from ipython>=6.1.0->ipywidgets>=7.5.1->pandas-profiling==2.7.1) (2.0.9)\n",
      "Requirement already satisfied: jedi>=0.10 in /home/valentina/anaconda3/lib/python3.7/site-packages (from ipython>=6.1.0->ipywidgets>=7.5.1->pandas-profiling==2.7.1) (0.13.3)\n",
      "Requirement already satisfied: pickleshare in /home/valentina/anaconda3/lib/python3.7/site-packages (from ipython>=6.1.0->ipywidgets>=7.5.1->pandas-profiling==2.7.1) (0.7.5)\n",
      "Requirement already satisfied: backcall in /home/valentina/anaconda3/lib/python3.7/site-packages (from ipython>=6.1.0->ipywidgets>=7.5.1->pandas-profiling==2.7.1) (0.1.0)\n",
      "Requirement already satisfied: jupyter-core in /home/valentina/anaconda3/lib/python3.7/site-packages (from jupyter-client->ipykernel>=4.5.1->ipywidgets>=7.5.1->pandas-profiling==2.7.1) (4.5.0)\n",
      "Requirement already satisfied: pyzmq>=13 in /home/valentina/anaconda3/lib/python3.7/site-packages (from jupyter-client->ipykernel>=4.5.1->ipywidgets>=7.5.1->pandas-profiling==2.7.1) (18.0.0)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /home/valentina/anaconda3/lib/python3.7/site-packages (from pexpect; sys_platform != \"win32\"->ipython>=6.1.0->ipywidgets>=7.5.1->pandas-profiling==2.7.1) (0.6.0)\n",
      "Requirement already satisfied: wcwidth in /home/valentina/anaconda3/lib/python3.7/site-packages (from prompt-toolkit<2.1.0,>=2.0.0->ipython>=6.1.0->ipywidgets>=7.5.1->pandas-profiling==2.7.1) (0.1.7)\n",
      "Requirement already satisfied: parso>=0.3.0 in /home/valentina/anaconda3/lib/python3.7/site-packages (from jedi>=0.10->ipython>=6.1.0->ipywidgets>=7.5.1->pandas-profiling==2.7.1) (0.5.0)\n",
      "Building wheels for collected packages: pandas, phik\n",
      "  Building wheel for pandas (PEP 517) ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /home/valentina/.cache/pip/wheels/5c/f4/45/389dc711f0c5ff9adeb5245397ab18bf75182e8cff9fbfa916\n",
      "  Building wheel for phik (PEP 517) ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /home/valentina/.cache/pip/wheels/61/73/87/197f78ba68ebfa7f4b39a883d817fe2ed5b14c6ef7a06452b8\n",
      "Successfully built pandas phik\n",
      "Building wheels for collected packages: htmlmin, MarkupSafe\n",
      "  Building wheel for htmlmin (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /home/valentina/.cache/pip/wheels/43/07/ac/7c5a9d708d65247ac1f94066cf1db075540b85716c30255459\n",
      "  Building wheel for MarkupSafe (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /home/valentina/.cache/pip/wheels/f5/40/34/d60ef965622011684037ea53e53fd44ef58ed2062f26878ce2\n",
      "Successfully built htmlmin MarkupSafe\n",
      "\u001b[31mERROR: conda 4.10.1 requires ruamel_yaml_conda>=0.11.14, which is not installed.\u001b[0m\n",
      "\u001b[31mERROR: matplotlib 3.5.3 has requirement pillow>=6.2.0, but you'll have pillow 6.1.0 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: phik 0.12.2 has requirement joblib>=0.14.1, but you'll have joblib 0.13.2 which is incompatible.\u001b[0m\n",
      "Installing collected packages: scipy, pyerfa, astropy, pandas, tangled-up-in-unicode, attrs, networkx, imagehash, visions, packaging, fonttools, matplotlib, MarkupSafe, jinja2, phik, htmlmin, widgetsnbextension, jupyterlab-widgets, ipywidgets, missingno, charset-normalizer, requests, confuse, pandas-profiling\n",
      "  Found existing installation: scipy 1.3.0\n",
      "    Uninstalling scipy-1.3.0:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Successfully uninstalled scipy-1.3.0\n",
      "  Found existing installation: astropy 3.2.1\n",
      "    Uninstalling astropy-3.2.1:\n",
      "      Successfully uninstalled astropy-3.2.1\n",
      "  Found existing installation: pandas 0.24.2\n",
      "    Uninstalling pandas-0.24.2:\n",
      "      Successfully uninstalled pandas-0.24.2\n",
      "  Found existing installation: attrs 19.1.0\n",
      "    Uninstalling attrs-19.1.0:\n",
      "      Successfully uninstalled attrs-19.1.0\n",
      "  Found existing installation: networkx 2.3\n",
      "    Uninstalling networkx-2.3:\n",
      "      Successfully uninstalled networkx-2.3\n",
      "  Found existing installation: packaging 19.0\n",
      "    Uninstalling packaging-19.0:\n",
      "      Successfully uninstalled packaging-19.0\n",
      "  Found existing installation: matplotlib 3.1.0\n",
      "    Uninstalling matplotlib-3.1.0:\n",
      "      Successfully uninstalled matplotlib-3.1.0\n",
      "  Found existing installation: MarkupSafe 1.1.1\n",
      "    Uninstalling MarkupSafe-1.1.1:\n",
      "      Successfully uninstalled MarkupSafe-1.1.1\n",
      "  Found existing installation: Jinja2 2.10.1\n",
      "    Uninstalling Jinja2-2.10.1:\n",
      "      Successfully uninstalled Jinja2-2.10.1\n",
      "  Found existing installation: widgetsnbextension 3.5.0\n",
      "    Uninstalling widgetsnbextension-3.5.0:\n",
      "      Successfully uninstalled widgetsnbextension-3.5.0\n",
      "  Found existing installation: ipywidgets 7.5.0\n",
      "    Uninstalling ipywidgets-7.5.0:\n",
      "      Successfully uninstalled ipywidgets-7.5.0\n",
      "  Found existing installation: requests 2.22.0\n",
      "    Uninstalling requests-2.22.0:\n",
      "      Successfully uninstalled requests-2.22.0\n",
      "Successfully installed MarkupSafe-2.1.1 astropy-4.3.1 attrs-22.1.0 charset-normalizer-2.1.1 confuse-2.0.0 fonttools-4.37.4 htmlmin-0.1.12 imagehash-4.3.1 ipywidgets-8.0.2 jinja2-3.1.2 jupyterlab-widgets-3.0.3 matplotlib-3.5.3 missingno-0.5.1 networkx-2.6.3 packaging-21.3 pandas-1.3.5 pandas-profiling-2.7.1 phik-0.12.2 pyerfa-2.0.0.1 requests-2.28.1 scipy-1.7.3 tangled-up-in-unicode-0.2.0 visions-0.4.1 widgetsnbextension-4.0.3\n"
     ]
    }
   ],
   "source": [
    " # librería para manejar las flexiones gramaticales en el idioma inglés.\n",
    "!pip install inflect\n",
    "!pip install pandas-profiling==2.7.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/valentina/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " # librería Natural Language Toolkit, usada para trabajar con textos \n",
    "import nltk\n",
    "# Punkt permite separar un texto en frases.\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/valentina/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Descarga todas las palabras vacias, es decir, aquellas que no aportan nada al significado del texto\n",
    "# ¿Cuales son esas palabras vacías?\n",
    "\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /home/valentina/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " # Descarga de paquete WordNetLemmatizer, este es usado para encontrar el lema de cada palabra\n",
    "# ¿Qué es el lema de una palabra? ¿Qué tan dificil puede ser obtenerlo, piensa en el caso en que tuvieras que escribir la función que realiza esta tarea?\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting escape\n",
      "  Downloading https://files.pythonhosted.org/packages/6d/9c/72a72a1a5f16772bcfee1293304d073f776859feded195d020c6f3de37c1/escape-1.1-py2.py3-none-any.whl\n",
      "Installing collected packages: escape\n",
      "Successfully installed escape-1.1\n"
     ]
    }
   ],
   "source": [
    "!pip install escape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/valentina/anaconda3/lib/python3.7/site-packages/pandas/compat/_optional.py:138: UserWarning: Pandas requires version '2.7.0' or newer of 'numexpr' (version '2.6.9' currently installed).\n",
      "  warnings.warn(msg, UserWarning)\n"
     ]
    }
   ],
   "source": [
    "# Instalación de librerias\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys\n",
    "#from pandas_profiling import ProfileReport\n",
    "\n",
    "import re, string, unicodedata\n",
    "import contractions\n",
    "import inflect\n",
    "from nltk import word_tokenize, sent_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import LancasterStemmer, WordNetLemmatizer\n",
    "\n",
    "from sklearn.model_selection import train_test_split,GridSearchCV\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer, HashingVectorizer\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import BaggingClassifier, RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.metrics import classification_report, confusion_matrix, plot_precision_recall_curve\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perfilamiento y entendimiento de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    " # Uso de la libreria pandas para la lectura de archivos\n",
    "data = pd.read_csv('DatosSuicidio/SuicidiosProyecto.csv', sep=',', encoding = 'utf-8')\n",
    "# Asignación a una nueva variable de los datos leidos\n",
    "data_t=data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>text</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>173271</td>\n",
       "      <td>i want to destroy myselffor once everything wa...</td>\n",
       "      <td>suicide</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>336321</td>\n",
       "      <td>I kinda got behind schedule with learning for ...</td>\n",
       "      <td>non-suicide</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>256637</td>\n",
       "      <td>I'm just not sure anymoreFirst and foremost: I...</td>\n",
       "      <td>suicide</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>303772</td>\n",
       "      <td>please give me a reason to liveThats too much ...</td>\n",
       "      <td>suicide</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>293747</td>\n",
       "      <td>27f struggling to find meaning moving forwardI...</td>\n",
       "      <td>suicide</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                               text        class\n",
       "0      173271  i want to destroy myselffor once everything wa...      suicide\n",
       "1      336321  I kinda got behind schedule with learning for ...  non-suicide\n",
       "2      256637  I'm just not sure anymoreFirst and foremost: I...      suicide\n",
       "3      303772  please give me a reason to liveThats too much ...      suicide\n",
       "4      293747  27f struggling to find meaning moving forwardI...      suicide"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_t.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entendimiento de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statistics import mode\n",
    "\n",
    "textos = data_t.copy()\n",
    "textos['Conteo'] = [len(x) for x in textos['text']]\n",
    "textos['Moda'] = [[mode([len(x) for x in i.split(' ')])][0] for i in textos['text']]\n",
    "textos['Max'] = [[max([len(x) for x in i.split(' ')])][0] for i in textos['text']]\n",
    "textos['Min'] = [[min([len(x) for x in i.split(' ')])][0] for i in textos['text']]\n",
    "\n",
    "# Se realiza un perfilamiento de los datos con la librería pandas profiling\n",
    "ProfileReport(textos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparación de datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Limpieza de los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_non_ascii(words):\n",
    "    \"\"\"Remove non-ASCII characters from list of tokenized words\"\"\"\n",
    "    new_words = []\n",
    "    for word in words:\n",
    "        new_word = unicodedata.normalize('NFKD', word).encode('ascii', 'ignore').decode('utf-8', 'ignore')\n",
    "        new_words.append(new_word)\n",
    "    return new_words\n",
    "\n",
    "def to_lowercase(words):\n",
    "    \"\"\"Convert all characters to lowercase from list of tokenized words\"\"\"\n",
    "    new_words = words.lower()        \n",
    "    return new_words\n",
    "\n",
    "def remove_punctuation(words):\n",
    "    \"\"\"Remove punctuation from list of tokenized words\"\"\"\n",
    "    new_words = []\n",
    "    for word in words:\n",
    "        new_word = re.sub(r'[^\\w\\s]', '', word)\n",
    "        if new_word != '':\n",
    "            new_words.append(new_word)\n",
    "    return new_words\n",
    "\n",
    "def replace_numbers(words):\n",
    "    \"\"\"Replace all interger occurrences in list of tokenized words with textual representation\"\"\"\n",
    "    p = inflect.engine()\n",
    "    new_words = []\n",
    "    for word in words:\n",
    "        if word.isdigit():\n",
    "            new_word = p.number_to_words(word)\n",
    "            new_words.append(new_word)\n",
    "        else:\n",
    "            new_words.append(word)\n",
    "    return new_words\n",
    "\n",
    "def remove_stopwords(words):\n",
    "    \"\"\"Remove stop words from list of tokenized words\"\"\"\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    filtered_sentence = [w for w in words if not w.lower() in stop_words]\n",
    "    filtered_sentence = []\n",
    "    for w in words:\n",
    "        if w not in stop_words:\n",
    "            filtered_sentence.append(w)\n",
    "    return filtered_sentence\n",
    "\n",
    "def preprocessing(words):\n",
    "    words = to_lowercase(words)\n",
    "    words = replace_numbers(words)\n",
    "    words = remove_punctuation(words)\n",
    "    words = remove_non_ascii(words)\n",
    "    words = remove_stopwords(words)\n",
    "    return words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenización"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 146915/195700 [00:08<00:02, 17964.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "144603 İ am losing my mind...İ dont know how i can endure this bullshit ...  \n",
      "İam 21 and suffered almost every stage of my life , things are not going on my way , worst thing is everyone hates me even my family too . They think iam a failure.\n",
      "İam an university student but my grades like an  rotten apple on the tree... i have no motivation or energy. And dont have a girlfriend still virgin . Why i should keep up for nothing ?,  for more suffer ? or more failure ?\n",
      "İ just want peace , love and some money...\n",
      "İ know there is still some hope but i tired keep fighting it is pointless , i hate it i just want some victory . İ am looking for a gun but it is hard to access on my country . İ just dont want hurt anymore... it is enough.  İf people interested in motivational videos please watch \n",
      "(Why we choose suicide Mark Henic) it relaxed me one bit . İ need your prays too\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 195700/195700 [00:10<00:00, 18204.62it/s]\n"
     ]
    }
   ],
   "source": [
    "for t in tqdm(range(len(data_t))):\n",
    "    try:\n",
    "        contractions.fix(data_t['text'][t])\n",
    "    except:\n",
    "        print(t,data_t['text'][t])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/195700 [00:00<?, ?it/s]/home/valentina/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      " 74%|███████▍  | 144598/195700 [09:55<04:10, 204.31it/s]/home/valentina/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"\n",
      " 74%|███████▍  | 144664/195700 [09:56<04:00, 212.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "144603 I am losing my mind...I do not know how i can endure this bullshit ...  \n",
      "Iam 21 and suffered almost every stage of my life , things are not going on my way , worst thing is everyone hates me even my family too . They think iam a failure.\n",
      "Iam an university student but my grades like an  rotten apple on the tree... i have no motivation or energy. And do not have a girlfriend still virgin . Why i should keep up for nothing ?,  for more suffer ? or more failure ?\n",
      "I just want peace , love and some money...\n",
      "I know there is still some hope but i tired keep fighting it is pointless , i hate it i just want some victory . I am looking for a gun but it is hard to access on my country . I just do not want hurt anymore... it is enough.  If people interested in motivational videos please watch \n",
      "(Why we choose suicide Mark Henic) it relaxed me one bit . I need your prays too\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 195700/195700 [13:07<00:00, 248.62it/s]\n"
     ]
    }
   ],
   "source": [
    "for t in tqdm(range(len(data_t))):\n",
    "    try:\n",
    "         data_t['text'][t] = contractions.fix(data_t['text'][t])\n",
    "    except:\n",
    "        data_t['text'][t] = contractions.fix(''.join(remove_non_ascii(data_t['text'][t])))\n",
    "        print(t,data_t['text'][t])\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_t.to_csv(\"contractions.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_t['words'] = data_t['text'].apply(word_tokenize) #Aplica la eliminación del ruido\n",
    "data_t.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/195700 [00:00<?, ?it/s]/home/valentina/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      " 29%|██▉       | 57395/195700 [05:29<12:56, 178.12it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57369 I was bored so I tried to find some digits of π... 3,14159265358979323846264338327950288419716939937510582097494459230781640628620\r\n",
      " 899862803482534211706798214808651328230664709384460955058223172535940812848111\r\n",
      " 745028410270193852110555964462294895493038196442881097566593344612847564823378\r\n",
      " 678316527120190914564856692346034861045432664821339360726024914127372458700660\r\n",
      " 631558817488152092096282925409171536436789259036001133053054882046652138414695\r\n",
      " 194151160943305727036575959195309218611738193261179310511854807446237996274956\r\n",
      " 735188575272489122793818301194912983367336244065664308602139494639522473719070\r\n",
      " 217986094370277053921717629317675238467481846766940513200056812714526356082778\r\n",
      " 577134275778960917363717872146844090122495343014654958537105079227968925892354\r\n",
      " 201995611212902196086403441815981362977477130996051870721134999999837297804995\r\n",
      " 105973173281609631859502445945534690830264252230825334468503526193118817101000\r\n",
      " 313783875288658753320838142061717766914730359825349042875546873115956286388235\r\n",
      " 378759375195778185778053217122680661300192787661119590921642019893809525720106\r\n",
      " 548586327886593615338182796823030195203530185296899577362259941389124972177528\r\n",
      " 347913151557485724245415069595082953311686172785588907509838175463746493931925\r\n",
      " 506040092770167113900984882401285836160356370766010471018194295559619894676783\r\n",
      " 744944825537977472684710404753464620804668425906949129331367702898915210475216\r\n",
      " 205696602405803815019351125338243003558764024749647326391419927260426992279678\r\n",
      " 235478163600934172164121992458631503028618297455570674983850549458858692699569\r\n",
      " 092721079750930295532116534498720275596023648066549911988183479775356636980742\r\n",
      " 654252786255181841757467289097777279380008164706001614524919217321721477235014\r\n",
      " 144197356854816136115735255213347574184946843852332390739414333454776241686251\r\n",
      " 898356948556209921922218427255025425688767179049460165346680498862723279178608\r\n",
      " 578438382796797668145410095388378636095068006422512520511739298489608412848862\r\n",
      " 694560424196528502221066118630674427862203919494504712371378696095636437191728\r\n",
      " 746776465757396241389086583264599581339047802759009946576407895126946839835259\r\n",
      " 570982582262052248940772671947826848260147699090264013639443745530506820349625\r\n",
      " 245174939965143142980919065925093722169646151570985838741059788595977297549893\r\n",
      " 016175392846813826868386894277415599185592524595395943104997252468084598727364\r\n",
      " 469584865383673622262609912460805124388439045124413654976278079771569143599770\r\n",
      " 012961608944169486855584840635342207222582848864815845602850601684273945226746\r\n",
      " 767889525213852254995466672782398645659611635488623057745649803559363456817432\r\n",
      " 411251507606947945109659609402522887971089314566913686722874894056010150330861\r\n",
      " 792868092087476091782493858900971490967598526136554978189312978482168299894872\r\n",
      " 265880485756401427047755513237964145152374623436454285844479526586782105114135\r\n",
      " 473573952311342716610213596953623144295248493718711014576540359027993440374200\r\n",
      " 731057853906219838744780847848968332144571386875194350643021845319104848100537\r\n",
      " 061468067491927819119793995206141966342875444064374512371819217999839101591956\r\n",
      " 181467514269123974894090718649423196156794520809514655022523160388193014209376\r\n",
      " 213785595663893778708303906979207734672218256259966150142150306803844773454920\r\n",
      " 260541466592520149744285073251866600213243408819071048633173464965145390579626\r\n",
      " 856100550810665879699816357473638405257145910289706414011097120628043903975951\r\n",
      " 567715770042033786993600723055876317635942187312514712053292819182618612586732\r\n",
      " 157919841484882916447060957527069572209175671167229109816909152801735067127485\r\n",
      " 832228718352093539657251210835791513698820914442100675103346711031412671113699\r\n",
      " 086585163983150197016515116851714376576183515565088490998985998238734552833163\r\n",
      " 550764791853589322618548963213293308985706420467525907091548141654985946163718\r\n",
      " 027098199430992448895757128289059232332609729971208443357326548938239119325974\r\n",
      " 636673058360414281388303203824903758985243744170291327656180937734440307074692\r\n",
      " 112019130203303801976211011004492932151608424448596376698389522868478312355265\r\n",
      " 821314495768572624334418930396864262434107732269780280731891544110104468232527\r\n",
      " 162010526522721116603966655730925471105578537634668206531098965269186205647693\r\n",
      " 125705863566201855810072936065987648611791045334885034611365768675324944166803\r\n",
      " 962657978771855608455296541266540853061434443185867697514566140680070023787765\r\n",
      " 913440171274947042056223053899456131407112700040785473326993908145466464588079\r\n",
      " 727082668306343285878569830523580893306575740679545716377525420211495576158140\r\n",
      " 025012622859413021647155097925923099079654737612551765675135751782966645477917\r\n",
      " 450112996148903046399471329621073404375189573596145890193897131117904297828564\r\n",
      " 750320319869151402870808599048010941214722131794764777262241425485454033215718\r\n",
      " 530614228813758504306332175182979866223717215916077166925474873898665494945011\r\n",
      " 465406284336639379003976926567214638530673609657120918076383271664162748888007\r\n",
      " 869256029022847210403172118608204190004229661711963779213375751149595015660496\r\n",
      " 318629472654736425230817703675159067350235072835405670403867435136222247715891\r\n",
      " 504953098444893330963408780769325993978054193414473774418426312986080998886874\r\n",
      " 132604721569516239658645730216315981931951673538129741677294786724229246543668\r\n",
      " 009806769282382806899640048243540370141631496589794092432378969070697794223625\r\n",
      " 082216889573837986230015937764716512289357860158816175578297352334460428151262\r\n",
      " 720373431465319777741603199066554187639792933441952154134189948544473456738316\r\n",
      " 249934191318148092777710386387734317720754565453220777092120190516609628049092\r\n",
      " 636019759882816133231666365286193266863360627356763035447762803504507772355471\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|████▏     | 80971/195700 [07:48<11:16, 169.57it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80946 This is a test post to see if I can post here. This is some text because the post will get removed if it is too short.\n",
      "\n",
      "9696948398844824631575296531192802557143689208443001389288988866647042248354171400235928696944986727\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|█████▋    | 112221/195700 [11:04<08:16, 168.29it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "112190 34895704483281583042437503838291044899025448849810161712936080214455502109208029816756870778097936399390940477962 5485700232036262327746841663183613796330578267486647623042309953491116556066830174746167569457109488540119463986843431337291775458716534425805410001410751351260329493003057986761122301906898997032745014348241818705491889172207793699634988682046657656333825385117333560036615841996405076723361102393115544175508921080297172490\n",
      "\n",
      "A **basic** puzzle.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|██████▋   | 130045/195700 [12:51<06:14, 175.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130015 So I was going to post some art...but considering the new rules... 111111111111111111111111111111111111111111111111111111111\n",
      "111111111111111111111111111111111¶¶¶111111111111111111111\n",
      "111111111111111111111111111111¶¶¶¶11111111111111111111111\n",
      "1111111111111111111111111111¶¶¶¶1111111111111111111111111\n",
      "11111111111111111111111111¶¶¶¶¶¶1111111111111111111111111\n",
      "111111111111111111111111¶¶¶¶¶¶1111¶¶¶11¶¶¶¶¶¶¶¶¶¶¶¶¶¶¶111\n",
      "111111111111111¶¶¶¶¶¶¶¶¶¶¶¶¶¶¶¶¶¶¶¶¶¶¶¶¶¶¶¶¶¶¶¶¶111111111\n",
      "11111111111111111¶¶¶¶¶¶¶¶¶¶¶¶¶¶¶¶¶¶¶¶¶¶¶¶¶¶¶¶111111111111\n",
      "11111111111111111111¶¶¶¶¶¶¶¶¶¶¶¶¶¶¶¶¶¶¶¶¶¶¶¶¶¶¶¶¶¶¶¶¶1111\n",
      "1111111111111111¶¶¶¶¶¶¶¶¶¶¶¶¶¶¶¶¶¶¶¶¶¶¶¶¶¶¶¶¶¶¶1111111111\n",
      "111111111111111¶¶¶111¶¶¶¶¶¶¶¶¶¶¶¶¶¶¶¶¶¶¶¶¶¶¶¶¶¶¶¶¶1111111\n",
      "111111111111¶¶¶¶¶11¶¶¶¶¶¶¶¶¶¶¶11¶¶¶¶¶¶¶¶¶¶¶¶¶¶¶¶¶¶¶111111\n",
      "11111111111¶¶¶¶¶¶¶¶¶¶¶¶¶¶¶1¶¶1111¶¶¶¶¶¶¶¶¶¶¶¶¶11¶¶¶¶¶1111\n",
      "1111111¶¶¶¶¶¶¶¶¶¶¶¶¶¶¶¶¶¶111¶11111¶¶¶¶¶¶¶¶¶¶¶¶¶111¶¶¶¶111\n",
      "11111¶¶¶¶¶¶¶¶¶¶¶¶¶¶¶¶¶¶¶111111111¶¶¶¶¶¶¶¶¶¶¶¶¶¶¶1111¶¶¶11\n",
      "1111¶¶¶¶¶¶¶¶111111111111111111111¶¶¶¶¶¶¶¶¶¶¶¶¶¶¶¶11111¶¶1\n",
      "11111¶¶¶¶¶111111111111111111111¶¶¶¶¶¶¶¶¶¶¶¶¶¶¶¶¶¶11111111\n",
      "1111111¶1111111111111111111¶¶¶¶¶¶¶¶¶¶¶¶¶¶¶¶¶¶¶¶¶¶¶1111111\n",
      "1111111111111¶¶¶¶¶¶¶¶¶¶¶¶¶¶¶¶¶¶¶¶¶¶¶¶¶¶¶¶¶¶¶¶¶¶¶¶¶1111111\n",
      "111111111111111¶¶¶¶¶¶¶¶¶¶¶¶¶¶¶¶¶¶¶¶¶¶¶¶¶¶¶¶11¶¶¶¶¶1111111\n",
      "11111111111¶¶¶¶¶¶¶¶¶¶¶¶¶¶¶¶¶¶¶¶¶¶¶¶¶¶¶¶¶¶1111¶¶¶¶¶1111111\n",
      "11111111¶¶¶¶¶¶¶¶¶¶¶¶¶¶¶¶¶¶¶¶¶¶¶¶¶¶¶¶¶¶¶¶111111¶¶¶¶1111111\n",
      "111111¶¶¶¶¶¶¶¶¶¶¶¶¶¶¶¶¶¶¶¶¶¶¶¶¶¶¶¶¶¶¶111111111¶¶¶¶1111111\n",
      "1111¶¶¶¶¶¶¶¶¶¶¶¶¶¶¶¶¶¶¶¶¶¶¶¶¶¶¶¶¶¶¶11111111111¶¶¶¶1111111\n",
      "111¶¶¶¶¶¶¶¶¶¶¶¶¶¶¶¶¶¶¶111¶¶¶¶¶¶111111111111111¶¶¶11111111\n",
      "11¶¶¶¶¶¶¶¶¶¶¶¶¶¶¶¶1111111111111111111111111111¶¶111111111\n",
      "1¶¶¶¶¶¶¶¶¶¶¶¶¶¶¶11111111111111111¶¶1111111111111111111111\n",
      "¶¶¶¶¶¶¶¶¶¶¶¶¶¶¶111111111111111111111¶¶¶¶11111111111111111\n",
      "¶¶¶¶¶¶¶¶¶¶1¶¶¶111111111111111111111111¶¶¶¶¶11111111111111\n",
      "¶¶¶¶¶¶¶¶¶¶11¶¶11111111111111111111111111¶¶¶¶¶¶¶1111111111\n",
      "¶¶¶¶¶¶¶¶¶¶¶111¶111111111111¶¶¶11111¶¶¶¶111¶¶¶¶¶¶¶11111111\n",
      "¶¶¶¶¶¶¶¶¶¶¶¶11111111111111111¶¶¶11111¶¶¶¶¶¶¶¶¶¶¶¶¶¶111111\n",
      "¶¶¶¶¶¶¶¶¶¶¶¶¶¶¶11111111111111¶¶¶¶¶¶¶¶¶¶¶¶¶¶¶¶¶¶¶¶¶¶¶¶1111\n",
      "¶1¶¶¶¶¶¶¶¶¶¶¶¶¶¶¶¶¶111111111¶¶¶¶¶¶¶¶¶¶¶¶¶¶¶¶¶¶¶¶¶¶¶¶¶¶¶11\n",
      "¶¶11¶¶¶¶¶¶¶¶¶¶¶¶111111111¶¶¶¶¶¶¶¶¶¶¶¶¶¶¶¶111¶¶¶¶¶¶¶¶¶¶¶¶1\n",
      "1¶11¶¶¶¶¶¶¶¶¶¶¶¶¶¶¶¶¶¶¶¶¶¶¶¶¶¶¶¶¶¶¶¶¶¶11111111111¶¶¶¶¶¶¶¶\n",
      "1111¶¶¶¶¶¶¶¶¶¶¶¶¶¶¶¶¶¶¶¶¶¶¶¶¶¶¶¶¶¶¶¶¶11111111111111¶¶¶¶¶¶\n",
      "1111¶¶¶¶¶1¶¶¶¶¶¶¶¶¶¶¶¶¶¶¶¶¶¶11¶¶¶¶¶¶¶¶11111111111111¶¶¶¶¶\n",
      "11111¶¶¶11111¶¶¶¶¶¶¶¶¶¶¶¶¶11111¶¶¶¶¶¶¶¶¶¶11111111111111¶¶\n",
      "1111¶¶¶11111111¶¶¶1¶¶¶¶¶¶¶¶¶11111¶¶¶¶¶11111111111111111¶¶\n",
      "1111¶¶¶111111111111111¶¶¶¶¶¶¶1111111¶¶¶¶¶¶¶¶111111111111¶\n",
      "11111¶¶1111111111111111111¶¶¶¶¶1111111111111111111111111¶\n",
      "111111¶11111111111111111111¶¶¶¶11111111111111111111111111\n",
      "1111111111111111111111111111¶¶¶11111111111111111111111111\n",
      "11111111111111111111111111111¶¶11111111111111111111111111\n",
      "111111111111111111111111111111111111111111111111111111111\n",
      "111111111111111111111111111111111111111111111111111111111\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|████████▏ | 161338/195700 [16:11<03:46, 151.45it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "161319 Its 5am, pm me if you want, as my sleep schedule is the worst thing ever. (Insert 1000000000000000000000000000000000000000000000000000000000 fillers here)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|█████████▎| 183323/195700 [18:26<01:23, 147.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "183292 Rick Roll in binary code \n",
      "0101011101100101001001110111001001100101001000000110111001101111001000000111001101110100011100100110000101101110011001110110010101110010011100110010000001110100011011110010000001101100011011110111011001100101000010100101100101101111011101010010000001101011011011100110111101110111001000000111010001101000011001010010000001110010011101010110110001100101011100110010000001100001011011100110010000100000011100110110111100100000011001000110111100100000010010010000101001000001001000000110011001110101011011000110110000100000011000110110111101101101011011010110100101110100011011010110010101101110011101000010011101110011001000000111011101101000011000010111010000100000010010010010011101101101001000000111010001101000011010010110111001101011011010010110111001100111001000000110111101100110000010100101100101101111011101010010000001110111011011110111010101101100011001000110111000100111011101000010000001100111011001010111010000100000011101000110100001101001011100110010000001100110011100100110111101101101001000000110000101101110011110010010000001101111011101000110100001100101011100100010000001100111011101010111100100001010000010100100100100100000011010100111010101110011011101000010000001110111011000010110111001101110011000010010000001110100011001010110110001101100001000000111100101101111011101010010000001101000011011110111011100100000010010010010011101101101001000000110011001100101011001010110110001101001011011100110011100001010010001110110111101110100011101000110000100100000011011010110000101101011011001010010000001111001011011110111010100100000011101010110111001100100011001010111001001110011011101000110000101101110011001000000101000001010010011100110010101110110011001010111001000100000011001110110111101101110011011100110000100100000011001110110100101110110011001010010000001111001011011110111010100100000011101010111000000001010010011100110010101110110011001010111001000100000011001110110111101101110011011100110000100100000011011000110010101110100001000000111100101101111011101010010000001100100011011110111011101101110000010100100111001100101011101100110010101110010001000000110011101101111011011100110111001100001001000000111001001110101011011100010000001100001011100100110111101110101011011100110010000100000011000010110111001100100001000000110010001100101011100110110010101110010011101000010000001111001011011110111010100001010010011100110010101110110011001010111001000100000011001110110111101101110011011100110000100100000011011010110000101101011011001010010000001111001011011110111010100100000011000110111001001111001000010100100111001100101011101100110010101110010001000000110011101101111011011100110111001100001001000000111001101100001011110010010000001100111011011110110111101100100011000100111100101100101000010100100111001100101011101100110010101110010001000000110011101101111011011100110111001100001001000000111010001100101011011000110110000100000011000010010000001101100011010010110010100100000011000010110111001100100001000000110100001110101011100100111010000100000011110010110111101110101\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 195700/195700 [19:41<00:00, 165.67it/s]\n"
     ]
    }
   ],
   "source": [
    "for t in tqdm(range(len(data_t))):\n",
    "    try:\n",
    "        data_t['text'][t]=remove_stopwords(remove_non_ascii(remove_punctuation(replace_numbers(word_tokenize(to_lowercase(data_t['text'][t]))))))\n",
    "    except:\n",
    "        print(t,data_t['text'][t])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_t=data_t.drop([57369,80946,112190,130015,161319,183292])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>text</th>\n",
       "      <th>class</th>\n",
       "      <th>words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>173271</td>\n",
       "      <td>[want, destroy, myselffor, everyth, start, fee...</td>\n",
       "      <td>suicide</td>\n",
       "      <td>want destroy myselffor everyth start feel okay...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>336321</td>\n",
       "      <td>[kind, got, behind, schedul, learn, next, week...</td>\n",
       "      <td>non-suicide</td>\n",
       "      <td>kind got behind schedul learn next week testwe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>256637</td>\n",
       "      <td>[sure, anymorefirst, foremost, brazil, judg, s...</td>\n",
       "      <td>suicide</td>\n",
       "      <td>sure anymorefirst foremost brazil judg second ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>303772</td>\n",
       "      <td>[pleas, give, reason, livethat, much, reason, ...</td>\n",
       "      <td>suicide</td>\n",
       "      <td>pleas give reason livethat much reason live li...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>293747</td>\n",
       "      <td>[27f, struggl, find, mean, move, forwardi, adm...</td>\n",
       "      <td>suicide</td>\n",
       "      <td>27f struggl find mean move forwardi admit bit ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195695</th>\n",
       "      <td>248038</td>\n",
       "      <td>[drop, cool, new, cereal, idea, like, would, i...</td>\n",
       "      <td>non-suicide</td>\n",
       "      <td>drop cool new cereal idea like would ideal cer...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195696</th>\n",
       "      <td>216516</td>\n",
       "      <td>[unpopular, opinion, cat, deserv, love, respec...</td>\n",
       "      <td>non-suicide</td>\n",
       "      <td>unpopular opinion cat deserv love respect much...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195697</th>\n",
       "      <td>199341</td>\n",
       "      <td>[hey, guy, doin, hey, guy, doin]</td>\n",
       "      <td>non-suicide</td>\n",
       "      <td>hey guy doin hey guy doin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195698</th>\n",
       "      <td>145373</td>\n",
       "      <td>[uhm, cover, dog, blanket, light, wake, woke, ...</td>\n",
       "      <td>non-suicide</td>\n",
       "      <td>uhm cover dog blanket light wake woke ran wall...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195699</th>\n",
       "      <td>305170</td>\n",
       "      <td>[____god, end, life, tire, could, want, anyth,...</td>\n",
       "      <td>suicide</td>\n",
       "      <td>____god end life tire could want anyth need so...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>195694 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Unnamed: 0                                               text  \\\n",
       "0           173271  [want, destroy, myselffor, everyth, start, fee...   \n",
       "1           336321  [kind, got, behind, schedul, learn, next, week...   \n",
       "2           256637  [sure, anymorefirst, foremost, brazil, judg, s...   \n",
       "3           303772  [pleas, give, reason, livethat, much, reason, ...   \n",
       "4           293747  [27f, struggl, find, mean, move, forwardi, adm...   \n",
       "...            ...                                                ...   \n",
       "195695      248038  [drop, cool, new, cereal, idea, like, would, i...   \n",
       "195696      216516  [unpopular, opinion, cat, deserv, love, respec...   \n",
       "195697      199341                   [hey, guy, doin, hey, guy, doin]   \n",
       "195698      145373  [uhm, cover, dog, blanket, light, wake, woke, ...   \n",
       "195699      305170  [____god, end, life, tire, could, want, anyth,...   \n",
       "\n",
       "              class                                              words  \n",
       "0           suicide  want destroy myselffor everyth start feel okay...  \n",
       "1       non-suicide  kind got behind schedul learn next week testwe...  \n",
       "2           suicide  sure anymorefirst foremost brazil judg second ...  \n",
       "3           suicide  pleas give reason livethat much reason live li...  \n",
       "4           suicide  27f struggl find mean move forwardi admit bit ...  \n",
       "...             ...                                                ...  \n",
       "195695  non-suicide  drop cool new cereal idea like would ideal cer...  \n",
       "195696  non-suicide  unpopular opinion cat deserv love respect much...  \n",
       "195697  non-suicide                          hey guy doin hey guy doin  \n",
       "195698  non-suicide  uhm cover dog blanket light wake woke ran wall...  \n",
       "195699      suicide  ____god end life tire could want anyth need so...  \n",
       "\n",
       "[195694 rows x 4 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_t.to_csv(\"preprocessing.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>text</th>\n",
       "      <th>class</th>\n",
       "      <th>words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>173271</td>\n",
       "      <td>[want, destroy, myselffor, everyth, start, fee...</td>\n",
       "      <td>suicide</td>\n",
       "      <td>want destroy myselffor everyth start feel okay...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>336321</td>\n",
       "      <td>[kind, got, behind, schedul, learn, next, week...</td>\n",
       "      <td>non-suicide</td>\n",
       "      <td>kind got behind schedul learn next week testwe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>256637</td>\n",
       "      <td>[sure, anymorefirst, foremost, brazil, judg, s...</td>\n",
       "      <td>suicide</td>\n",
       "      <td>sure anymorefirst foremost brazil judg second ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>303772</td>\n",
       "      <td>[pleas, give, reason, livethat, much, reason, ...</td>\n",
       "      <td>suicide</td>\n",
       "      <td>pleas give reason livethat much reason live li...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>293747</td>\n",
       "      <td>[27f, struggl, find, mean, move, forwardi, adm...</td>\n",
       "      <td>suicide</td>\n",
       "      <td>27f struggl find mean move forwardi admit bit ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                               text        class  \\\n",
       "0      173271  [want, destroy, myselffor, everyth, start, fee...      suicide   \n",
       "1      336321  [kind, got, behind, schedul, learn, next, week...  non-suicide   \n",
       "2      256637  [sure, anymorefirst, foremost, brazil, judg, s...      suicide   \n",
       "3      303772  [pleas, give, reason, livethat, much, reason, ...      suicide   \n",
       "4      293747  [27f, struggl, find, mean, move, forwardi, adm...      suicide   \n",
       "\n",
       "                                               words  \n",
       "0  want destroy myselffor everyth start feel okay...  \n",
       "1  kind got behind schedul learn next week testwe...  \n",
       "2  sure anymorefirst foremost brazil judg second ...  \n",
       "3  pleas give reason livethat much reason live li...  \n",
       "4  27f struggl find mean move forwardi admit bit ...  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_t.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalización"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>text</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>173271</td>\n",
       "      <td>[want, destroy, myselffor, everyth, start, fee...</td>\n",
       "      <td>suicide</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>336321</td>\n",
       "      <td>[kind, got, behind, schedul, learn, next, week...</td>\n",
       "      <td>non-suicide</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>256637</td>\n",
       "      <td>[sure, anymorefirst, foremost, brazil, judg, s...</td>\n",
       "      <td>suicide</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>303772</td>\n",
       "      <td>[pleas, give, reason, livethat, much, reason, ...</td>\n",
       "      <td>suicide</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>293747</td>\n",
       "      <td>[27f, struggl, find, mean, move, forwardi, adm...</td>\n",
       "      <td>suicide</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                               text        class\n",
       "0      173271  [want, destroy, myselffor, everyth, start, fee...      suicide\n",
       "1      336321  [kind, got, behind, schedul, learn, next, week...  non-suicide\n",
       "2      256637  [sure, anymorefirst, foremost, brazil, judg, s...      suicide\n",
       "3      303772  [pleas, give, reason, livethat, much, reason, ...      suicide\n",
       "4      293747  [27f, struggl, find, mean, move, forwardi, adm...      suicide"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "porter = PorterStemmer()\n",
    "wordnet_lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def stem_words(words):\n",
    "    \"\"\"Stem words in list of tokenized words\"\"\"\n",
    "    stem_sentence=[]\n",
    "    for word in words:\n",
    "        stem_sentence.append(porter.stem(word))\n",
    "    return stem_sentence\n",
    "\n",
    "def lemmatize_verbs(words):\n",
    "    \"\"\"Lemmatize verbs in list of tokenized words\"\"\"\n",
    "    stem_sentence=[]\n",
    "    for word in words:\n",
    "        stem_sentence.append(wordnet_lemmatizer.lemmatize(word))\n",
    "    return stem_sentence\n",
    "\n",
    "def stem_and_lemmatize(words):\n",
    "    stems = stem_words(words)\n",
    "    lemmas = lemmatize_verbs(words)\n",
    "    return stems + lemmas\n",
    "\n",
    "data_t['text'] = data_t['text'].apply(stem_and_lemmatize) #Aplica lematización y Eliminación de Prefijos y Sufijos.\n",
    "data_t.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_t.to_csv(\"normalizacion.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['want',\n",
       " 'destroy',\n",
       " 'myselffor',\n",
       " 'everyth',\n",
       " 'start',\n",
       " 'feel',\n",
       " 'okay',\n",
       " 'came',\n",
       " 'tumbl',\n",
       " 'know',\n",
       " 'use',\n",
       " 'cope',\n",
       " 'reason',\n",
       " 'tear',\n",
       " 'skin',\n",
       " 'shred',\n",
       " 'swallow',\n",
       " 'everi',\n",
       " 'pill',\n",
       " 'find',\n",
       " 'right',\n",
       " 'alon',\n",
       " 'room',\n",
       " 'wall',\n",
       " 'slowli',\n",
       " 'fall',\n",
       " 'matter',\n",
       " 'time',\n",
       " 'snap',\n",
       " 'final',\n",
       " 'end',\n",
       " 'want',\n",
       " 'destroy',\n",
       " 'myselffor',\n",
       " 'everything',\n",
       " 'starting',\n",
       " 'feel',\n",
       " 'okay',\n",
       " 'came',\n",
       " 'tumbling',\n",
       " 'know',\n",
       " 'used',\n",
       " 'cope',\n",
       " 'reason',\n",
       " 'tearing',\n",
       " 'skin',\n",
       " 'shred',\n",
       " 'swallowing',\n",
       " 'every',\n",
       " 'pill',\n",
       " 'find',\n",
       " 'right',\n",
       " 'alone',\n",
       " 'room',\n",
       " 'wall',\n",
       " 'slowly',\n",
       " 'falling',\n",
       " 'matter',\n",
       " 'time',\n",
       " 'snap',\n",
       " 'finally',\n",
       " 'end']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_t['text'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selección de campos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>text</th>\n",
       "      <th>class</th>\n",
       "      <th>words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>173271</td>\n",
       "      <td>[want, destroy, myselffor, everyth, start, fee...</td>\n",
       "      <td>suicide</td>\n",
       "      <td>[want, destroy, myselffor, everyth, start, fee...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>336321</td>\n",
       "      <td>[kind, got, behind, schedul, learn, next, week...</td>\n",
       "      <td>non-suicide</td>\n",
       "      <td>[kind, got, behind, schedul, learn, next, week...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>256637</td>\n",
       "      <td>[sure, anymorefirst, foremost, brazil, judg, s...</td>\n",
       "      <td>suicide</td>\n",
       "      <td>[sure, anymorefirst, foremost, brazil, judg, s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>303772</td>\n",
       "      <td>[pleas, give, reason, livethat, much, reason, ...</td>\n",
       "      <td>suicide</td>\n",
       "      <td>[pleas, give, reason, livethat, much, reason, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>293747</td>\n",
       "      <td>[27f, struggl, find, mean, move, forwardi, adm...</td>\n",
       "      <td>suicide</td>\n",
       "      <td>[27f, struggl, find, mean, move, forwardi, adm...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                               text        class  \\\n",
       "0      173271  [want, destroy, myselffor, everyth, start, fee...      suicide   \n",
       "1      336321  [kind, got, behind, schedul, learn, next, week...  non-suicide   \n",
       "2      256637  [sure, anymorefirst, foremost, brazil, judg, s...      suicide   \n",
       "3      303772  [pleas, give, reason, livethat, much, reason, ...      suicide   \n",
       "4      293747  [27f, struggl, find, mean, move, forwardi, adm...      suicide   \n",
       "\n",
       "                                               words  \n",
       "0  [want, destroy, myselffor, everyth, start, fee...  \n",
       "1  [kind, got, behind, schedul, learn, next, week...  \n",
       "2  [sure, anymorefirst, foremost, brazil, judg, s...  \n",
       "3  [pleas, give, reason, livethat, much, reason, ...  \n",
       "4  [27f, struggl, find, mean, move, forwardi, adm...  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_t['words']=data_t['text']\n",
    "data_t.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>text</th>\n",
       "      <th>class</th>\n",
       "      <th>words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>173271</td>\n",
       "      <td>[want, destroy, myselffor, everyth, start, fee...</td>\n",
       "      <td>suicide</td>\n",
       "      <td>want destroy myselffor everyth start feel okay...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>336321</td>\n",
       "      <td>[kind, got, behind, schedul, learn, next, week...</td>\n",
       "      <td>non-suicide</td>\n",
       "      <td>kind got behind schedul learn next week testwe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>256637</td>\n",
       "      <td>[sure, anymorefirst, foremost, brazil, judg, s...</td>\n",
       "      <td>suicide</td>\n",
       "      <td>sure anymorefirst foremost brazil judg second ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>303772</td>\n",
       "      <td>[pleas, give, reason, livethat, much, reason, ...</td>\n",
       "      <td>suicide</td>\n",
       "      <td>pleas give reason livethat much reason live li...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>293747</td>\n",
       "      <td>[27f, struggl, find, mean, move, forwardi, adm...</td>\n",
       "      <td>suicide</td>\n",
       "      <td>27f struggl find mean move forwardi admit bit ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195695</th>\n",
       "      <td>248038</td>\n",
       "      <td>[drop, cool, new, cereal, idea, like, would, i...</td>\n",
       "      <td>non-suicide</td>\n",
       "      <td>drop cool new cereal idea like would ideal cer...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195696</th>\n",
       "      <td>216516</td>\n",
       "      <td>[unpopular, opinion, cat, deserv, love, respec...</td>\n",
       "      <td>non-suicide</td>\n",
       "      <td>unpopular opinion cat deserv love respect much...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195697</th>\n",
       "      <td>199341</td>\n",
       "      <td>[hey, guy, doin, hey, guy, doin]</td>\n",
       "      <td>non-suicide</td>\n",
       "      <td>hey guy doin hey guy doin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195698</th>\n",
       "      <td>145373</td>\n",
       "      <td>[uhm, cover, dog, blanket, light, wake, woke, ...</td>\n",
       "      <td>non-suicide</td>\n",
       "      <td>uhm cover dog blanket light wake woke ran wall...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195699</th>\n",
       "      <td>305170</td>\n",
       "      <td>[____god, end, life, tire, could, want, anyth,...</td>\n",
       "      <td>suicide</td>\n",
       "      <td>____god end life tire could want anyth need so...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>195700 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Unnamed: 0                                               text  \\\n",
       "0           173271  [want, destroy, myselffor, everyth, start, fee...   \n",
       "1           336321  [kind, got, behind, schedul, learn, next, week...   \n",
       "2           256637  [sure, anymorefirst, foremost, brazil, judg, s...   \n",
       "3           303772  [pleas, give, reason, livethat, much, reason, ...   \n",
       "4           293747  [27f, struggl, find, mean, move, forwardi, adm...   \n",
       "...            ...                                                ...   \n",
       "195695      248038  [drop, cool, new, cereal, idea, like, would, i...   \n",
       "195696      216516  [unpopular, opinion, cat, deserv, love, respec...   \n",
       "195697      199341                   [hey, guy, doin, hey, guy, doin]   \n",
       "195698      145373  [uhm, cover, dog, blanket, light, wake, woke, ...   \n",
       "195699      305170  [____god, end, life, tire, could, want, anyth,...   \n",
       "\n",
       "              class                                              words  \n",
       "0           suicide  want destroy myselffor everyth start feel okay...  \n",
       "1       non-suicide  kind got behind schedul learn next week testwe...  \n",
       "2           suicide  sure anymorefirst foremost brazil judg second ...  \n",
       "3           suicide  pleas give reason livethat much reason live li...  \n",
       "4           suicide  27f struggl find mean move forwardi admit bit ...  \n",
       "...             ...                                                ...  \n",
       "195695  non-suicide  drop cool new cereal idea like would ideal cer...  \n",
       "195696  non-suicide  unpopular opinion cat deserv love respect much...  \n",
       "195697  non-suicide                          hey guy doin hey guy doin  \n",
       "195698  non-suicide  uhm cover dog blanket light wake woke ran wall...  \n",
       "195699      suicide  ____god end life tire could want anyth need so...  \n",
       "\n",
       "[195700 rows x 4 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_t['words'] = data_t['words'].apply(lambda x: ' '.join(map(str, x)))\n",
    "data_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_t.to_csv(\"join.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         1\n",
       "1         0\n",
       "2         1\n",
       "3         1\n",
       "4         1\n",
       "         ..\n",
       "195695    0\n",
       "195696    0\n",
       "195697    0\n",
       "195698    0\n",
       "195699    1\n",
       "Name: class, Length: 195694, dtype: int64"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_data, y_data = data_t['words'],data_t['class']\n",
    "y_data = (y_data == 'suicide').astype(int)\n",
    "y_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Expected 2D array, got 1D array instead:\narray=['want destroy myselffor everyth start feel okay came tumbl know use cope reason tear skin shred swallow everi pill find right alon room wall slowli fall matter time snap final end want destroy myselffor everything starting feel okay came tumbling know used cope reason tearing skin shred swallowing every pill find right alone room wall slowly falling matter time snap finally end'\n 'kind got behind schedul learn next week testweek eight test four alreadi studi two studi good two minim four anyth yet still three day option pull three nighter tell parent tell freak still possibl super hard kind got behind schedule learning next week testweek eight test four already studied two studied good two minimal four anything yet still three day option pull three nighters tell parent tell freak still possible super hard'\n 'sure anymorefirst foremost brazil judg second never went doctor see realli form depress think whatev sure care anymor know thing someday thing make avoid suicid fear come next thank anxieti cool scare recent start studi start read random shit nihil definili agre argument life mean feel like sinc 10 seventeen sometim fuck hard cope peopl around constantli hide realli feel sometim use dark though mind make joke sinc peopl believ think believ die three sleep worst year life honestli know make ps talk famili hate care guy take care put unfinish dream use trophi hate parent almost hate sure anymorefirst foremost brazil judge second never went doctor see really form depression think whatever sure care anymore know thing somedays thing make avoid suicide fear coming next thank anxiety cool scare recently started study started reading random shit nihilism definily agree argument life meaning feel like since 10 seventeen sometimes fucking hard cope people around constantly hide really feel sometimes using dark thoughs mind make joke since people believe think believe die three sleep worst year life honestly know make p talk family hate care guy taking care put unfinished dream use trophy hate parentes almost hate'\n ... 'hey guy doin hey guy doin'\n 'uhm cover dog blanket light wake woke ran wall uhm covered dog blanket light wake woke ran wall'\n '____god end life tire could want anyth need someon could stab shoot anyth anyth would take loan could guarante death ____god end life tired could want anything need someone could stab shoot anything anything would take loan could guarantee death'].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-36-640930c4d020>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m clf = BaggingClassifier(base_estimator=SVC(),\n\u001b[0;32m----> 2\u001b[0;31m                         n_estimators=10, random_state=0).fit(X_data, y_data)\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_bagging.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    265\u001b[0m             \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    266\u001b[0m             \u001b[0mforce_all_finite\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 267\u001b[0;31m             \u001b[0mmulti_output\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    268\u001b[0m         )\n\u001b[1;32m    269\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_samples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36m_validate_data\u001b[0;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[1;32m    579\u001b[0m                 \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_y_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    580\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 581\u001b[0;31m                 \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_X_y\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    582\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    583\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_X_y\u001b[0;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[1;32m    974\u001b[0m         \u001b[0mensure_min_samples\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mensure_min_samples\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    975\u001b[0m         \u001b[0mensure_min_features\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mensure_min_features\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 976\u001b[0;31m         \u001b[0mestimator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    977\u001b[0m     )\n\u001b[1;32m    978\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator)\u001b[0m\n\u001b[1;32m    771\u001b[0m                     \u001b[0;34m\"Reshape your data either using array.reshape(-1, 1) if \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    772\u001b[0m                     \u001b[0;34m\"your data has a single feature or array.reshape(1, -1) \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 773\u001b[0;31m                     \u001b[0;34m\"if it contains a single sample.\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    774\u001b[0m                 )\n\u001b[1;32m    775\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Expected 2D array, got 1D array instead:\narray=['want destroy myselffor everyth start feel okay came tumbl know use cope reason tear skin shred swallow everi pill find right alon room wall slowli fall matter time snap final end want destroy myselffor everything starting feel okay came tumbling know used cope reason tearing skin shred swallowing every pill find right alone room wall slowly falling matter time snap finally end'\n 'kind got behind schedul learn next week testweek eight test four alreadi studi two studi good two minim four anyth yet still three day option pull three nighter tell parent tell freak still possibl super hard kind got behind schedule learning next week testweek eight test four already studied two studied good two minimal four anything yet still three day option pull three nighters tell parent tell freak still possible super hard'\n 'sure anymorefirst foremost brazil judg second never went doctor see realli form depress think whatev sure care anymor know thing someday thing make avoid suicid fear come next thank anxieti cool scare recent start studi start read random shit nihil definili agre argument life mean feel like sinc 10 seventeen sometim fuck hard cope peopl around constantli hide realli feel sometim use dark though mind make joke sinc peopl believ think believ die three sleep worst year life honestli know make ps talk famili hate care guy take care put unfinish dream use trophi hate parent almost hate sure anymorefirst foremost brazil judge second never went doctor see really form depression think whatever sure care anymore know thing somedays thing make avoid suicide fear coming next thank anxiety cool scare recently started study started reading random shit nihilism definily agree argument life meaning feel like since 10 seventeen sometimes fucking hard cope people around constantly hide really feel sometimes using dark thoughs mind make joke since people believe think believe die three sleep worst year life honestly know make p talk family hate care guy taking care put unfinished dream use trophy hate parentes almost hate'\n ... 'hey guy doin hey guy doin'\n 'uhm cover dog blanket light wake woke ran wall uhm covered dog blanket light wake woke ran wall'\n '____god end life tire could want anyth need someon could stab shoot anyth anyth would take loan could guarante death ____god end life tired could want anything need someone could stab shoot anything anything would take loan could guarantee death'].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample."
     ]
    }
   ],
   "source": [
    "clf = BaggingClassifier(base_estimator=SVC(),\n",
    "                        n_estimators=10, random_state=0).fit(X_data, y_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(195700, 213345)\n"
     ]
    },
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 311. GiB for an array with shape (195700, 213345) and data type int64",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-27-8572b2332be1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mX_dummy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdummy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_dummy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mX_dummy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/scipy/sparse/compressed.py\u001b[0m in \u001b[0;36mtoarray\u001b[0;34m(self, order, out)\u001b[0m\n\u001b[1;32m   1037\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0morder\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m             \u001b[0morder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_swap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'cf'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_process_toarray_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1040\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflags\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mc_contiguous\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflags\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf_contiguous\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Output array must be C or F contiguous'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/scipy/sparse/base.py\u001b[0m in \u001b[0;36m_process_toarray_args\u001b[0;34m(self, order, out)\u001b[0m\n\u001b[1;32m   1200\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1201\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1202\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1203\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1204\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mMemoryError\u001b[0m: Unable to allocate 311. GiB for an array with shape (195700, 213345) and data type int64"
     ]
    }
   ],
   "source": [
    "dummy = CountVectorizer(binary=True)\n",
    "X_dummy = dummy.fit_transform(X_data)\n",
    "print(X_dummy.shape)\n",
    "X_dummy.toarray()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(195700, 213345)\n"
     ]
    },
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 311. GiB for an array with shape (195700, 213345) and data type int64",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-28-bf1db242fb14>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mX_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcount\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_count\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mX_count\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/scipy/sparse/compressed.py\u001b[0m in \u001b[0;36mtoarray\u001b[0;34m(self, order, out)\u001b[0m\n\u001b[1;32m   1037\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0morder\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m             \u001b[0morder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_swap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'cf'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_process_toarray_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1040\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflags\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mc_contiguous\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflags\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf_contiguous\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Output array must be C or F contiguous'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/scipy/sparse/base.py\u001b[0m in \u001b[0;36m_process_toarray_args\u001b[0;34m(self, order, out)\u001b[0m\n\u001b[1;32m   1200\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1201\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1202\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1203\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1204\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mMemoryError\u001b[0m: Unable to allocate 311. GiB for an array with shape (195700, 213345) and data type int64"
     ]
    }
   ],
   "source": [
    "count = CountVectorizer()\n",
    "X_count = count.fit_transform(X_data)\n",
    "print(X_count.shape)\n",
    "X_count.toarray()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " tf_idf = ...\n",
    "\n",
    "print(X_tf_idf.shape)\n",
    "X_tf_idf.toarray()[0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
